{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tonchan1216/bitbot/blob/master/q-learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation, rc\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, ReLU\n",
        "from keras.optimizers import RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmdGv30Hd5dW"
      },
      "outputs": [],
      "source": [
        "class Envrionment:\n",
        "  def __init__(self) :\n",
        "      self.reset()\n",
        "\n",
        "  def reset(self):\n",
        "    self.t = 0\n",
        "    self.finished = False\n",
        "    self.profits = 0\n",
        "\n",
        "  def step(self, act):\n",
        "    self.t += 1\n",
        "\n",
        "class Brain:\n",
        "  def __init__(self, n_state, n_mid, n_action, gamma=0.9, r=0.99):\n",
        "    self.eps = 1.0\n",
        "    self.gamma = gamma\n",
        "    self.r = r\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Dense(n_mid, input_shape=(n_state,)))\n",
        "    model.add(ReLLU())\n",
        "    model.add(Dense(n_mid))\n",
        "    model.add(ReLLU())\n",
        "    model.add(Dense(n_action))\n",
        "    model.compile(loss=\"mse\", optimizer=optimizers)\n",
        "    self.model = model\n",
        "\n",
        "  def train(self, states, next_states, action, reward, terminal):\n",
        "    q = self.model.predict(states)\n",
        "    next_q = self.model.predict(next_states)\n",
        "    t = np.copy(q)\n",
        "\n",
        "    if terminal:\n",
        "      t[:, action] = reward\n",
        "    else:\n",
        "      t[:, action] = reward + self.gamma * np.max(next_q, axis = 1)\n",
        "\n",
        "    self.model.tarin_on_batch(state, t)\n",
        "\n",
        "    def get_action(self, states):\n",
        "      q = self.model.predict(states)\n",
        "      if np.random.rand() < self.eps:\n",
        "        action = np.random.randint(q.shapse[1], size=q.shape[0])\n",
        "      else:\n",
        "        action = np.argmax(q, axis = 1)\n",
        "\n",
        "      if self.eps > 0.1:\n",
        "        self.eps *= self.r\n",
        "      return action\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Agent:\n",
        "  def __init__(self, brain) :\n",
        "    self.brain = brain\n",
        "    self.reset()\n",
        "\n",
        "  def reset(self):\n",
        "    pass\n",
        "\n",
        "  def step(self):\n",
        "    states = np.array([[]])\n",
        "\n",
        "    reward = 0\n",
        "    terminal = False\n",
        "\n",
        "    if True:\n",
        "      reward = 1\n",
        "      terminal = True\n",
        "    else:\n",
        "      reward = -1\n",
        "      terminal True\n",
        "\n",
        "    reward = np.array([reward])\n",
        "    action = self.brain.get_action(states)\n",
        "    if action:\n",
        "      pass\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "    next_states = np.array([])\n",
        "    brain.train(states, next_states, action, reward, terminal)\n",
        "\n",
        "    if terminal:\n",
        "      self.reset()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNfWJHnZR4oT+Q9RNozAePJ",
      "include_colab_link": true,
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
